{"pii": "S1877050917317568", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0001", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "cesectitle0001"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abss0001", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "spara0073", "view": "all"}, "_": "Systems based on wireless sensor have been presented as an alternative to location and navigation for visually impaired in environments where GPS is not effective. However, dealing with the information obtained from these sensors may present some challenges. The difficulties described by several authors are related mainly to the oscillation of the signals, which are susceptible to numerous interfering agents such as the scene itself, the presence of people, etc. It is necessary to increase the accuracy of the location in all the techniques observed. Therefore, this paper proposes to apply data fusion of wi-fi sensors with inertial sensors to allow visually impaired to location and navigation in indoor places using aspects of healthcare like sensor based systems embedded in wearable devices. The methodology adopted was associate redundant fusion and complementary fusion to construct a database obtained from several readings of the wi-fi sensors and an inertial sensor to construct a reference position to compare the data of the test readings to this reference and indicate the reliability in an indoor location. The results show that RSSI with SNR and magnetometer with gyroscope provide high error rates with raw and isolated data, but when fused, they show a more efficient location, decreasing the error rates observed in isolated mode. The error margins between the real position and the position indicated by the system were 0,386 m, 0,336 m and 0,148 m to RSSI with SNR, inertial and fusion application, respectively."}]}]}]}}