{"pii": "S0097849322000656", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "attachments", "$$": [{"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0097849322000656-ga1.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0097849322000656/ga1/DOWNSAMPLED/image/jpeg/2582b2cfdd8a1d9fc3d6ce2dcf5cf5f0/ga1.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "12998"}, {"#name": "pixel-height", "_": "121"}, {"#name": "pixel-width", "_": "301"}, {"#name": "attachment-type", "_": "IMAGE-DOWNSAMPLED"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0097849322000656-ga1.sml"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0097849322000656/ga1/THUMBNAIL/image/gif/a8cdbe5d25e3ca799d20f7e695367ed9/ga1.sml"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.sml"}, {"#name": "extension", "_": "sml"}, {"#name": "filesize", "_": "8654"}, {"#name": "pixel-height", "_": "88"}, {"#name": "pixel-width", "_": "219"}, {"#name": "attachment-type", "_": "IMAGE-THUMBNAIL"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0097849322000656-ga1_lrg.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0097849322000656/HIGHRES/image/jpeg/bbdf5034e444614c266605db970bdbc6/ga1_lrg.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1_lrg.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "103397"}, {"#name": "pixel-height", "_": "535"}, {"#name": "pixel-width", "_": "1333"}, {"#name": "attachment-type", "_": "IMAGE-HIGH-RES"}]}]}, {"#name": "abstract", "$": {"class": "author", "view": "all", "id": "d1e402"}, "$$": [{"#name": "section-title", "$": {"id": "d1e403"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"view": "all", "id": "d1e405"}, "$$": [{"#name": "simple-para", "$": {"view": "all", "id": "d1e406"}, "_": "Similarity maps show dimensionality-reduced activation vectors of a high number of data points and thereby can help to understand which features a neural network has learned from the data. However, similarity maps have severely limited expressiveness for large datasets with hundreds of thousands of data instances and thousands of labels, such as ImageNet or word2vec. In this work, we present \u201cconcept splatters\u201d as a scalable method to interactively explore similarities between data instances as learned by the machine through the lens of human-understandable semantics. Our approach enables interactive exploration of large latent spaces on multiple levels of abstraction. We present a web-based implementation that supports interactive exploration of tens of thousands of word vectors of word2vec and CNN feature vectors of ImageNet. In a qualitative study, users could effectively discover spurious learning strategies of the network, ambiguous labels, and could characterize reasons for potential confusion."}]}]}, {"#name": "abstract", "$": {"class": "graphical", "view": "all", "id": "d1e408"}, "$$": [{"#name": "section-title", "$": {"id": "d1e409"}, "_": "Graphical abstract"}, {"#name": "abstract-sec", "$": {"view": "all", "id": "d1e411"}, "$$": [{"#name": "simple-para", "$": {"view": "all", "id": "d1e412"}, "$$": [{"#name": "display", "$$": [{"#name": "figure", "$": {"id": "dfig1"}, "$$": [{"#name": "link", "$": {"xmlns:xlink": true, "locator": "ga1", "href": "pii:S0097849322000656/ga1", "role": "http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4", "id": "d1e416"}}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "view": "all", "id": "d1e417"}, "$$": [{"#name": "section-title", "$": {"id": "d1e418"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"view": "all", "id": "d1e420"}, "$$": [{"#name": "simple-para", "$": {"view": "all", "id": "d1e421"}, "$$": [{"#name": "list", "$": {"id": "d1e423"}, "$$": [{"#name": "list-item", "$": {"id": "d1e424"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e427"}, "_": "Multi-scale visualization for interactive exploration of large latent spaces."}]}, {"#name": "list-item", "$": {"id": "d1e429"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e432"}, "_": "Visual encoding principle based on prototype theory."}]}, {"#name": "list-item", "$": {"id": "d1e434"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e437"}, "_": "Online interface for visual exploration of ImageNet-trained CNNs and word2vec."}]}, {"#name": "list-item", "$": {"id": "d1e439"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e442"}, "_": "Multiple use cases visualize previously reported properties of neural networks."}]}]}]}]}]}]}}