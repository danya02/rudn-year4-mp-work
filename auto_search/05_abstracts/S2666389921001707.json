{"pii": "S2666389921001707", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0010", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0010"}, "_": "Summary"}, {"#name": "abstract-sec", "$": {"id": "abssec0010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0010", "view": "all"}, "$$": [{"#name": "__text__", "_": "Reproducible computational research (RCR) is the keystone of the scientific method for "}, {"#name": "italic", "_": "in silico"}, {"#name": "__text__", "_": " analyses, packaging the transformation of raw data to published results. In addition to its role in research integrity, improving the reproducibility of scientific studies can accelerate evaluation and reuse. This potential and wide support for the FAIR principles have motivated interest in metadata standards supporting reproducibility. Metadata provide context and provenance to raw data and methods and are essential to both discovery and validation. Despite this shared connection with scientific data, few studies have explicitly described how metadata enable reproducible computational research. This review employs a functional content analysis to identify metadata standards that support reproducibility across an analytic stack consisting of input data, tools, notebooks, pipelines, and publications. Our review provides background context, explores gaps, and discovers component trends of embeddedness and methodology weight from which we derive recommendations for future work."}]}]}]}, {"#name": "abstract", "$": {"class": "editor-highlights", "id": "abs0020", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0020"}, "_": "The bigger picture"}, {"#name": "abstract-sec", "$": {"id": "abssec0020", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0020", "view": "all"}, "$$": [{"#name": "__text__", "_": "A recent confluence of technologies has enabled scientists to effectively transfer runnable analyses, addressing a long-standing challenge of reproducible research. The implementation of reproducible research for "}, {"#name": "italic", "_": "in silico"}, {"#name": "__text__", "_": " analyses requires extensive metadata to describe both scientific concepts and the underlying computing environment. This review covers the wide range of metadata standards relevant to reproducible computational research across an \u201canalytic stack\u201d consisting of input data, tools, reports, pipelines, and publications. Legacy and cutting-edge metadata support a wide range of data annotations, analytic approaches, and interpretation across virtually all scientific disciplines. This review is designed to bridge the metadata and reproducible research communities. We identify competing approaches of embedded and connected metadata, discuss gaps, and make recommendations with implications for the future of journals and peer review."}]}]}]}, {"#name": "abstract", "$": {"class": "teaser", "id": "abs0025", "view": "all"}, "$$": [{"#name": "abstract-sec", "$": {"id": "abssec0025", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0025", "view": "all"}, "_": "Leipzig et\u00a0al. review the wide range of metadata standards for input data, tools, reports, pipelines, and publications that are enabling reproducible computational analyses with implications for the future of journals and peer review."}]}]}]}}