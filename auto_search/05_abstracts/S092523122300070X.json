{"pii": "S092523122300070X", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "attachments", "$$": [{"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S092523122300070X-ga1.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S092523122300070X/ga1/DOWNSAMPLED/image/jpeg/14103e249b7f9a9a8aaa4a830a841963/ga1.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "15878"}, {"#name": "pixel-height", "_": "200"}, {"#name": "pixel-width", "_": "247"}, {"#name": "attachment-type", "_": "IMAGE-DOWNSAMPLED"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S092523122300070X-ga1.sml"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S092523122300070X/ga1/THUMBNAIL/image/gif/0260f1b1b0e36d5f8813d0bb74fbd9fd/ga1.sml"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.sml"}, {"#name": "extension", "_": "sml"}, {"#name": "filesize", "_": "9110"}, {"#name": "pixel-height", "_": "163"}, {"#name": "pixel-width", "_": "202"}, {"#name": "attachment-type", "_": "IMAGE-THUMBNAIL"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S092523122300070X-ga1_lrg.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S092523122300070X/HIGHRES/image/jpeg/8c6059d76454ddf76c0470ede66b1ec5/ga1_lrg.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1_lrg.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "106139"}, {"#name": "pixel-height", "_": "886"}, {"#name": "pixel-width", "_": "1095"}, {"#name": "attachment-type", "_": "IMAGE-HIGH-RES"}]}]}, {"#name": "abstract", "$": {"class": "graphical", "lang": "en", "id": "ab005", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "st130"}, "_": "Graphical abstract"}, {"#name": "abstract-sec", "$": {"id": "as005", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp005", "view": "all"}, "$$": [{"#name": "display", "$$": [{"#name": "figure", "$": {"id": "f0065"}, "$$": [{"#name": "link", "$": {"xmlns:xlink": true, "locator": "ga1", "role": "http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4", "id": "lk005", "href": "pii:S092523122300070X/ga1"}}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "lang": "en", "id": "ab010", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "st135"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"id": "as010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp010", "view": "all"}, "$$": [{"#name": "list", "$": {"id": "l0005"}, "$$": [{"#name": "list-item", "$": {"id": "u0005"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0230", "view": "all"}, "_": "The dense feature adaptive connection module improves the quality of depth map."}]}, {"#name": "list-item", "$": {"id": "u0010"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0235", "view": "all"}, "_": "The distributed 3D convolution reduces the computational cost and memory space."}]}, {"#name": "list-item", "$": {"id": "u0015"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0240", "view": "all"}, "_": "The joint loss function makes the network sensitive to small depth structures."}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "author", "lang": "en", "id": "ab015", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "st140"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "as015", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp015", "view": "all"}, "_": "The goal of Multi-View Stereo is to reconstruct the 3D point cloud model from multiple views. With the development of deep learning, more and more learning-based research has achieved remarkable results. However, existing methods ignore the fine-grained features of the bottom layer, which leads to the poor quality of model reconstruction, especially in terms of completeness. Besides, current methods still rely on a large amount of consumed memory resources because of the application of 3D convolution. To this end, this paper proposes a Multiple Granularities Feature Fusion Network for Multi-View Stereo, an end-to-end depth estimation network combining global and local features, which is characterized by fine-granularity multi-feature fusion. Firstly, we propose a dense feature adaptive connection module, which can adaptively fuse the global and local features in the scene, provide a more complete and effective feature map for inferring a more detailed depth map, and make the ultimate model more complete. Secondly, in order to further improve the accuracy and completeness of the reconstructed point cloud, we introduce normal and edge loss futead of only using depth loss functions as in the existing methods, which makes the network more sensitive to small depth structures. Finally, we propose distributed 3D convolution instead of traditional 3D convolution, which reduces memory consumption. The experimental results on the DTU and Tanks & Temples datasets demonstrate that the proposed method in this papaer achieves the state-of-the-art performance, which proves the accuracy and effectiveness of the MG-MVSNet proposed in this paper."}]}]}]}}