{"pii": "S0262885624003986", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "ab0005", "lang": "en", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "st0005"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "as0005", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp0090", "view": "all"}, "_": "Automatic image annotation (AIA) is a fundamental and challenging task in computer vision. Considering the correlations between tags can lead to more accurate image understanding, benefiting various applications, including image retrieval and visual search. While many attempts have been made to incorporate tag correlations in annotation models, the method of constructing a knowledge graph based on external knowledge sources and hyperbolic space has not been explored. In this paper, we create an attributed knowledge graph based on vocabulary, integrate external knowledge sources such as WordNet, and utilize hyperbolic word embeddings for the tag representations. These embeddings provide a sophisticated tag representation that captures hierarchical and complex correlations more effectively, enhancing the image annotation results. In addition, leveraging external knowledge sources enhances contextuality and significantly enriches existing AIA datasets. We exploit two deep learning-based models, the Relational Graph Convolutional Network (R-GCN) and the Vision Transformer (ViT), to extract the input features. We apply two R-GCN operations to obtain word descriptors and fuse them with the extracted visual features. We evaluate the proposed approach using three public benchmark datasets. Our experimental results demonstrate that the proposed architecture achieves state-of-the-art performance across most metrics on Corel5k, ESP Game, and IAPRTC-12."}]}]}, {"#name": "abstract", "$": {"id": "ab0010", "class": "author-highlights", "lang": "en", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "st0010"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"id": "as0010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp0095", "view": "all"}, "$$": [{"#name": "list", "$": {"id": "l0005"}, "$$": [{"#name": "list-item", "$": {"id": "li0005"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0005", "view": "all"}, "_": "Knowledge graph with hyperbolic embeddings enhances automatic image annotation tags."}]}, {"#name": "list-item", "$": {"id": "li0010"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0010", "view": "all"}, "_": "External knowledge sources, like WordNet, enrich the annotation datasets."}]}, {"#name": "list-item", "$": {"id": "li0015"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0015", "view": "all"}, "_": "R-GCN and ViT models effectively fuse textual and visual features."}]}, {"#name": "list-item", "$": {"id": "li0020"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0020", "view": "all"}, "_": "Calibrated predictions refine class probabilities for more reliable annotations."}]}]}]}]}]}]}}