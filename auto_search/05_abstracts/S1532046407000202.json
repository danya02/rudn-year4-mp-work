{"pii": "S1532046407000202", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"class": "author", "lang": "en", "id": "aep-abstract-id12"}, "$$": [{"#name": "section-title", "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "aep-abstract-sec-id13"}, "$$": [{"#name": "simple-para", "$": {"view": "all"}, "$$": [{"#name": "__text__", "_": "The published medical literature and online medical resources are important sources to help physicians make patient treatment decisions. Traditional sources used for "}, {"#name": "italic", "_": "information retrieval"}, {"#name": "__text__", "_": " (e.g., PubMed) often return a list of documents in response to a user\u2019s query. Frequently the number of returned documents from large knowledge repositories is large and makes information seeking practical only \u201cafter hours\u201d and not in the clinical setting. This study developed novel algorithms, and designed, implemented, and evaluated a "}, {"#name": "italic", "_": "medical definitional question answering"}, {"#name": "__text__", "_": " system (MedQA). MedQA automatically analyzed a large number of electronic documents to generate short and coherent answers in response to definitional questions (i.e., questions with the format of \u201cWhat is X?\u201d). Our preliminary cognitive evaluation shows that MedQA out-performed three other online information systems (Google, OneLook, and PubMed) in two important efficiency criteria; namely, time spent and number of actions taken for a physician to identify a definition. It is our contention that question answering systems that aggregate pertinent information scattered across different documents have the potential to address clinical information needs within a timeframe necessary to meet the demands of clinicians."}]}]}]}]}}