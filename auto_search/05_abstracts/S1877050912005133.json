{"pii": "S1877050912005133", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"class": "author", "id": "aep-abstract-id7"}, "$$": [{"#name": "section-title", "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "aep-abstract-sec-id8"}, "$$": [{"#name": "simple-para", "$": {"id": "spar0005", "view": "all"}, "$$": [{"#name": "__text__", "_": "Connectivity is the basic factor for the proper operation of any wireless network. In a mobile wireless sensor network it is a challenge for applications and protocols to deal with connectivity problems, as links might get up and down frequently. In these scenarios, having knowledge of the node remaining connectivity time could both improve the performance of the protocols (e.g. handoff mechanisms) and save possible scarce nodes resources (CPU, bandwidth, and energy) by preventing unfruitful transmissions. The current paper provides a solution called "}, {"#name": "italic", "_": "Genetic Machine Learning Algorithm"}, {"#name": "__text__", "_": " (GMLA) to forecast the remainder connectivity time in mobile environments. It consists in combining Classifier Systems with a Markov chain model of the RF link quality. The main advantage of using an evolutionary approach is that the Markov model parameters can be discovered on-the-fly, making it possible to cope with unknown environments and mobility patterns. Simulation results show that the proposal is a very suitable solution, as it overcomes the performance obtained by similar approaches."}]}]}]}]}}