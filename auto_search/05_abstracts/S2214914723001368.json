{"pii": "S2214914723001368", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"lang": "en", "id": "abs0010", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0010"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abssec0010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0010", "view": "all"}, "_": "As positioning sensors, edge computation power, and communication technologies continue to develop, a moving agent can now sense its surroundings and communicate with other agents. By receiving spatial information from both its environment and other agents, an agent can use various methods and sensor types to localize itself. With its high flexibility and robustness, collaborative positioning has become a widely used method in both military and civilian applications. This paper introduces the basic fundamental concepts and applications of collaborative positioning, and reviews recent progress in the field based on camera, LiDAR (Light Detection and Ranging), wireless sensor, and their integration. The paper compares the current methods with respect to their sensor type, summarizes their main paradigms, and analyzes their evaluation experiments. Finally, the paper discusses the main challenges and open issues that require further research."}]}]}]}}