{"pii": "S1877050923016812", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0001", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "cesectitle0001"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abss0001", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "spara001", "view": "all"}, "_": "Uploading research articles to a database can be a complex process with multiple HTML fields. The complexity of this process makes users less efficient and productive. This study explored the use of the Multilayer Perceptron (MLP) algorithm using language-independent features (count and Boolean features) to create a multi-class text classifier that can classify 10 research article components (e.g., title, authors, abstract, etc.). The text classifier was developed to pave the way for a streamlined manual data entry process for uploading research articles to a database by implementing a single textarea in favor of using multiple HTML fields. The text samples were obtained from multiple sources using web scraping technology, consolidated, cleaned, and standardized. The 12 language-independent features were generated based on the textual formats of sample texts (e.g., count of capitalized letters, digits, punctuation, checking the existence of a URL pattern, etc.). Recursive feature elimination with cross validation (RFECV) was used to determine the optimal number of input features. The hyperparameter values of the model were determined through the grid search technique. A trial-and-error process was conducted to determine the number of hidden layers. The model achieved 95%, 94%, and 95% scores for micro, macro, and weighted average f1-scores, respectively. The model performed well in classifying research article components. However, it is sensitive to textual format (e.g., lower or upper case, punctuation used, etc.). For subsequent research in this area, this study recommends investigating the use of both language-dependent and language-independent features to address the limitations of the current model."}]}]}]}}