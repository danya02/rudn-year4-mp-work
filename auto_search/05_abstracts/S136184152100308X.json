{"pii": "S136184152100308X", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "attachments", "$$": [{"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S136184152100308X-ga1.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S136184152100308X/ga1/DOWNSAMPLED/image/jpeg/1028a243493df78696f47963d9911caf/ga1.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "13091"}, {"#name": "pixel-height", "_": "109"}, {"#name": "pixel-width", "_": "301"}, {"#name": "attachment-type", "_": "IMAGE-DOWNSAMPLED"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S136184152100308X-ga1.sml"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S136184152100308X/ga1/THUMBNAIL/image/gif/b87cf4994da863936e1e89722cfe2c68/ga1.sml"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.sml"}, {"#name": "extension", "_": "sml"}, {"#name": "filesize", "_": "6420"}, {"#name": "pixel-height", "_": "79"}, {"#name": "pixel-width", "_": "219"}, {"#name": "attachment-type", "_": "IMAGE-THUMBNAIL"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S136184152100308X-ga1_lrg.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S136184152100308X/ga1/HIGHRES/image/jpeg/2ed86a5b7209120118127b01ea9498fa/ga1_lrg.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1_lrg.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "125324"}, {"#name": "pixel-height", "_": "482"}, {"#name": "pixel-width", "_": "1333"}, {"#name": "attachment-type", "_": "IMAGE-HIGH-RES"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S136184152100308X-si48.svg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S136184152100308X/STRIPIN/image/svg+xml/3bdc3dbb98f27d576056bb180aa008f9/si48.svg"}, {"#name": "file-basename", "_": "si48"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "si48.svg"}, {"#name": "extension", "_": "svg"}, {"#name": "filesize", "_": "756"}, {"#name": "attachment-type", "_": "ALTIMG"}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "id": "absh001", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sctt0001"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"id": "abssec0001", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp0001", "view": "all"}, "$$": [{"#name": "list", "$": {"id": "lst0004"}, "$$": [{"#name": "list-item", "$": {"id": "lstitem0001"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0001", "view": "all"}, "_": "A novel vessel annotation and 3D segmentation learning framework using weak supervision through 2D patch tags as training labels."}]}, {"#name": "list-item", "$": {"id": "lstitem0002"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0002", "view": "all"}, "_": "A classifier network automatically generates training patch tags in unlabeled data without requiring user interactions."}]}, {"#name": "list-item", "$": {"id": "lstitem0003"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0003", "view": "all"}, "_": "The use of patch tags reduces the time needed to annotate a 3D image by up to 77% on average."}]}, {"#name": "list-item", "$": {"id": "lstitem0004"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0004", "view": "all"}, "_": "The novel weakly supervised learning framework achieves performance comparable to the state-of-the-art."}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "graphical", "id": "absh0002", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sctt0002"}, "_": "Graphical abstract"}, {"#name": "abstract-sec", "$": {"id": "abssec0002", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp0002", "view": "all"}, "$$": [{"#name": "display", "$$": [{"#name": "figure", "$": {"id": "fig0019"}, "$$": [{"#name": "link", "$": {"xmlns:xlink": true, "id": "celink0019", "locator": "ga1", "type": "simple", "role": "http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4", "href": "pii:S136184152100308X/ga1"}}]}]}]}]}]}, {"#name": "abstract", "$": {"id": "abs0001", "class": "author", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sctt0003"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abssec0003", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "sp0003", "view": "all"}, "$$": [{"#name": "__text__", "_": "Deep learning techniques for 3D brain vessel image segmentation have not been as successful as in the segmentation of other organs and tissues. This can be explained by two factors. First, deep learning techniques tend to show poor performances at the segmentation of relatively small objects compared to the size of the full image. Second, due to the complexity of vascular trees and the small size of vessels, it is challenging to obtain the amount of annotated training data typically needed by deep learning methods. To address these problems, we propose a novel annotation-efficient deep learning vessel segmentation framework. The framework avoids pixel-wise annotations, only requiring weak patch-level labels to discriminate between vessel and non-vessel 2D patches in the training set, in a setup similar to the CAPTCHAs used to differentiate humans from bots in web applications. The user-provided weak annotations are used for two tasks: (1) to synthesize pixel-wise pseudo-labels for vessels and background in each patch, which are used to train a segmentation network, and (2) to train a classifier network. The classifier network allows to generate additional weak patch labels, further reducing the annotation burden, and it acts as a second opinion for poor quality images. We use this framework for the segmentation of the cerebrovascular tree in Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The results show that the framework achieves state-of-the-art accuracy, while reducing the annotation time by "}, {"#name": "math", "$": {"xmlns:mml": true, "altimg": "si48.svg"}, "$$": [{"#name": "mo", "_": "\u223c"}]}, {"#name": "__text__", "_": "77% w.r.t. learning-based segmentation methods using pixel-wise labels for training."}]}]}]}]}}