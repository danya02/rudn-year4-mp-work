{"pii": "S0950705123005415", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"class": "author", "view": "all", "id": "d1e3294"}, "$$": [{"#name": "section-title", "$": {"id": "d1e3295"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"view": "all", "id": "d1e3297"}, "$$": [{"#name": "simple-para", "$": {"view": "all", "id": "d1e3298"}, "_": "A novel technology named fashion intelligence system, which quantifies ambiguous expressions unique to fashion, such as \u201ccasual,\u201d \u201cadult-casual,\u201d and \u201coffice-casual,\u201d was previously proposed to support users in their understanding of fashion. However, the existing visual-semantic embedding (VSE) model, which forms the basis of the system, does not support images that are composed of multiple parts, such as those containing hair, tops, trousers, skirts, and shoes. Therefore, we propose a partial VSE (PVSE) model, which enables fine-grained learning of each part of the fashion outfit. The proposed model learns embedded representations via angular-based contrastive learning. This helps in retaining three existing practical functionalities and further enables image-retrieval tasks where changes are only made to specified parts and image-reordering tasks focusing on the specified parts. In other words, the proposed model enables five types of practical functionalities, even with a simple structure. Through qualitative and quantitative experiments, we demonstrate that the proposed model is superior to conventional models, without increasing computational complexity."}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "view": "all", "id": "d1e3300"}, "$$": [{"#name": "section-title", "$": {"id": "d1e3301"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"view": "all", "id": "d1e3303"}, "$$": [{"#name": "simple-para", "$": {"view": "all", "id": "d1e3304"}, "$$": [{"#name": "list", "$": {"id": "d1e3306"}, "$$": [{"#name": "list-item", "$": {"id": "d1e3307"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e3310"}, "_": "Model to extend the system for interpreting ambiguous fashion expressions is proposed."}]}, {"#name": "list-item", "$": {"id": "d1e3312"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e3315"}, "_": "Partial visual-semantic embedding for fine-grained learning for each part is proposed."}]}, {"#name": "list-item", "$": {"id": "d1e3317"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e3320"}, "_": "Part-by-part representations can be obtained via angular-based contrastive learning."}]}, {"#name": "list-item", "$": {"id": "d1e3322"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e3325"}, "_": "Full-body outfit images are embedded with rich fashion-specific ambiguous expressions."}]}, {"#name": "list-item", "$": {"id": "d1e3327"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"view": "all", "id": "d1e3330"}, "_": "Multiple unique evaluation experiments demonstrate the effectiveness of the proposal."}]}]}]}]}]}]}}