{"pii": "S2666389923002222", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0010", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0010"}, "_": "Summary"}, {"#name": "abstract-sec", "$": {"id": "abssec0010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0010", "view": "all"}, "_": "This work introduces the EXSCLAIM! toolkit for the automatic extraction, separation, and caption-based natural language annotation of images from scientific literature. EXSCLAIM! is used to show how rule-based natural language processing and image recognition can be leveraged to construct an electron microscopy dataset containing thousands of keyword-annotated nanostructure images. Moreover, it is demonstrated how a combination of statistical topic modeling and semantic word similarity comparisons can be used to increase the number and variety of keyword annotations on top of the standard annotations from EXSCLAIM! With large-scale imaging datasets constructed from scientific literature, users are well positioned to train neural networks for classification and recognition tasks specific to microscopy\u2014tasks often otherwise inhibited by a lack of sufficient annotated training data."}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "id": "abs0020", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0020"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"id": "abssec0020", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0020", "view": "all"}, "$$": [{"#name": "list", "$": {"id": "ulist0010"}, "$$": [{"#name": "list-item", "$": {"id": "u0010"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0010", "view": "all"}, "_": "Software pipeline for creating self-annotated imaging datasets from science journals"}]}, {"#name": "list-item", "$": {"id": "u0015"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0015", "view": "all"}, "_": "Design uses configurable modules to scrape and process scientific figures/captions"}]}, {"#name": "list-item", "$": {"id": "u0020"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0020", "view": "all"}, "_": "Initial applications focus on materials microscopy, but techniques apply generally"}]}, {"#name": "list-item", "$": {"id": "u0025"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "p0025", "view": "all"}, "_": "Validation provided for figure separation and NLP caption distribution accuracy"}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "editor-highlights", "id": "abs0025", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0025"}, "_": "The bigger picture"}, {"#name": "abstract-sec", "$": {"id": "abssec0025", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0025", "view": "all"}, "_": "Due to recent improvements in image resolution and acquisition speed, materials microscopy is experiencing an explosion of published imaging data. The standard publication format, while sufficient for data ingestion scenarios where a selection of images can be critically examined and curated manually, is not conducive to large-scale data aggregation or analysis, hindering data sharing and reuse. Most images in publications are part of a larger figure, with their explicit context buried in the main body or caption text; so even if aggregated, collections of images with weak or no digitized contextual labels have limited value. The tool developed in this work establishes a scalable pipeline for meaningful image-/language-based information curation from scientific literature."}]}]}, {"#name": "abstract", "$": {"class": "teaser", "id": "abs0030", "view": "all"}, "$$": [{"#name": "abstract-sec", "$": {"id": "abssec0030", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0030", "view": "all"}, "_": "This study presents a software pipeline that uses computer vision and natural language processing approaches for automatic extraction, separation, and caption-based natural language annotation of images (EXSCLAIM!) from scientific literature and demonstrates its effectiveness in constructing a self-labeled electron microscopy dataset of nanostructure images. EXSCLAIM! is developed around materials microscopy images, but the approach is applicable to other scientific domains that produce high volumes of publications with joint image-text data (e.g., graphs, schematic illustrations, etc.)."}]}]}]}}