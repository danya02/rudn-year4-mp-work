{"pii": "S1877050916318828", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0005", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "sect0005"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abst0005", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "spar0005", "view": "all"}, "$$": [{"#name": "__text__", "_": "The need of humans to socialize and share information has led to a constantly growing Web, which has become a support for social media. Every day, worldwide users are pushing multimedia data towards their family, friends and the world at large. This is the reason why, web search has also become the main method for people to fulfill their information needs. The common modality used for image search on the web is based on text, the assumption being that the tags and the textual descriptions associated with photos are powerful ways to describe and retrieve images. The results are usually obtained by simply matching the terms of the query to an index of terms associated to the images in a corpus. The efficiency of this technique depends strongly on the tags associated to pictures, as well as their accuracy. Trying to search for images with bridges in this kind of systems, the result set will only contain images explicitly annotated with this term, but will fail to include images with "}, {"#name": "italic", "_": "Pont Neuf"}, {"#name": "__text__", "_": " or "}, {"#name": "italic", "_": "Ponte Vecchio"}, {"#name": "__text__", "_": ", if their tags do not contain the noun "}, {"#name": "italic", "_": "bridge"}, {"#name": "__text__", "_": ". In this paper, we present a system designed to perform diversification in an image retrieval system, using semantic resources like YAGO, Wikipedia and WordNet."}]}]}]}]}}