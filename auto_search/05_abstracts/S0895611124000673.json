{"pii": "S0895611124000673", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "attachments", "$$": [{"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0895611124000673-ga1.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0895611124000673/ga1/DOWNSAMPLED/image/jpeg/eacac5ab01c99fb016048ac3b1893f39/ga1.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "39985"}, {"#name": "pixel-height", "_": "120"}, {"#name": "pixel-width", "_": "301"}, {"#name": "attachment-type", "_": "IMAGE-DOWNSAMPLED"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0895611124000673-ga1.sml"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0895611124000673/ga1/THUMBNAIL/image/gif/d4cbfd36fed25f81cecb7f68dff0bcad/ga1.sml"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1.sml"}, {"#name": "extension", "_": "sml"}, {"#name": "filesize", "_": "25006"}, {"#name": "pixel-height", "_": "88"}, {"#name": "pixel-width", "_": "219"}, {"#name": "attachment-type", "_": "IMAGE-THUMBNAIL"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0895611124000673-ga1_lrg.jpg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0895611124000673/HIGHRES/image/jpeg/bb7b649fa77c250112957dcaca5f56fc/ga1_lrg.jpg"}, {"#name": "file-basename", "_": "ga1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "ga1_lrg.jpg"}, {"#name": "extension", "_": "jpg"}, {"#name": "filesize", "_": "255488"}, {"#name": "pixel-height", "_": "533"}, {"#name": "pixel-width", "_": "1333"}, {"#name": "attachment-type", "_": "IMAGE-HIGH-RES"}]}, {"#name": "attachment", "$": {"xmlns:xocs": true}, "$$": [{"#name": "attachment-eid", "_": "1-s2.0-S0895611124000673-si1.svg"}, {"#name": "ucs-locator", "_": "https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0895611124000673/image/svg+xml/9e56fe06d74c4ce1205d48474d3e4bdf/si1.svg"}, {"#name": "file-basename", "_": "si1"}, {"#name": "abstract-attachment", "_": "true"}, {"#name": "filename", "_": "si1.svg"}, {"#name": "extension", "_": "svg"}, {"#name": "filesize", "_": "5900"}, {"#name": "attachment-type", "_": "ALTIMG"}]}]}, {"#name": "abstract", "$": {"class": "author", "id": "d1e1371", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "d1e1372"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "d1e1374", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "d1e1375", "view": "all"}, "$$": [{"#name": "__text__", "_": "Colonoscopy is the choice procedure to diagnose, screening, and treat the colon and rectum cancer, from early detection of small precancerous lesions (polyps), to confirmation of malign masses. However, the high variability of the organ appearance and the complex shape of both the colon wall and structures of interest make this exploration difficult. Learned visuospatial and perceptual abilities mitigate technical limitations in clinical practice by proper estimation of the intestinal depth. This work introduces a novel methodology to estimate colon depth maps in single frames from monocular colonoscopy videos. The generated depth map is inferred from the shading variation of the colon wall with respect to the light source, as learned from a realistic synthetic database. Briefly, a classic convolutional neural network architecture is trained from scratch to estimate the depth map, improving sharp depth estimations in haustral folds and polyps by a custom loss function that minimizes the estimation error in edges and curvatures. The network was trained by a custom synthetic colonoscopy database herein constructed and released, composed of 248"}, {"#name": "hsp", "$": {"sp": "0.16667"}}, {"#name": "__text__", "_": "400 frames (47 videos), with depth annotations at the level of pixels. This collection comprehends 5 subsets of videos with progressively higher levels of visual complexity. Evaluation of the depth estimation with the synthetic database reached a threshold accuracy of 95.65%, and a mean-RMSE of "}, {"#name": "math", "$": {"xmlns:mml": true, "altimg": "si1.svg", "display": "inline", "id": "d1e1380"}, "$$": [{"#name": "mrow", "$$": [{"#name": "mn", "_": "0"}, {"#name": "mo", "_": "."}, {"#name": "mn", "_": "451"}, {"#name": "mi", "$": {"mathvariant": "normal"}, "_": "cm"}]}]}, {"#name": "__text__", "_": ", while a qualitative assessment with a real database showed consistent depth estimations, visually evaluated by the expert gastroenterologist coauthoring this paper. Finally, the method achieved competitive performance with respect to another state-of-the-art method using a public synthetic database and comparable results in a set of images with other five state-of-the-art methods. Additionally, three-dimensional reconstructions demonstrated useful approximations of the gastrointestinal tract geometry. Code for reproducing the reported results and the dataset are available at "}, {"#name": "inter-ref", "$": {"xmlns:xlink": true, "id": "interref2", "href": "https://github.com/Cimalab-unal/ColonDepthEstimation", "type": "simple"}, "_": "https://github.com/Cimalab-unal/ColonDepthEstimation"}, {"#name": "__text__", "_": "."}]}]}]}, {"#name": "abstract", "$": {"class": "graphical", "id": "d1e1394", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "d1e1395"}, "_": "Graphical abstract"}, {"#name": "abstract-sec", "$": {"id": "d1e1397", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "d1e1398", "view": "all"}, "$$": [{"#name": "display", "$$": [{"#name": "figure", "$": {"id": "dfig1"}, "$$": [{"#name": "link", "$": {"xmlns:xlink": true, "id": "d1e1402", "locator": "ga1", "href": "pii:S0895611124000673/ga1", "role": "http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"}}]}]}]}]}]}, {"#name": "abstract", "$": {"class": "author-highlights", "id": "d1e1403", "view": "all"}, "$$": [{"#name": "section-title", "$": {"id": "d1e1404"}, "_": "Highlights"}, {"#name": "abstract-sec", "$": {"id": "d1e1406", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "d1e1407", "view": "all"}, "$$": [{"#name": "list", "$": {"id": "d1e1409"}, "$$": [{"#name": "list-item", "$": {"id": "d1e1410"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "d1e1413", "view": "all"}, "_": "A convolutional neural network, the SfSNet, estimates a pixel-wise depth map of the colon in a raw frame from the colonoscopy video."}]}, {"#name": "list-item", "$": {"id": "d1e1415"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "d1e1418", "view": "all"}, "_": "A realistic synthetic colonoscopy database with depth annotations that is publicly available, with progressively higher levels of visual complexity."}]}, {"#name": "list-item", "$": {"id": "d1e1420"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "d1e1423", "view": "all"}, "_": "A custom loss function which drives the network by minimizing the estimation error at folds and polyps."}]}, {"#name": "list-item", "$": {"id": "d1e1425"}, "$$": [{"#name": "label", "_": "\u2022"}, {"#name": "para", "$": {"id": "d1e1428", "view": "all"}, "_": "Two training strategies are evaluated to optimize the depth estimation in colon folds and precancerous polyps."}]}]}]}]}]}]}}