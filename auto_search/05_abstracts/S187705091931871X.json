{"pii": "S187705091931871X", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"id": "abs0001", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "cesectitle0001"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abss0001", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "spara0103", "view": "all"}, "_": "In recent years continuous integration has become an important practice for pull-based software development. It helps developers make contributions flexibly to an isolated copy of the project\u2019s repository, create a pull request that represent such changes, and submit it to the project for evaluation. Despite its test centric approach, the ability of teams to scale up distributed development is limited by the manually demanding task of adding and updating labels to an issue report. Automating this step enables a project to produce quality results. We categorized issue reports to derive a specific classification of issue reports of pull-based development projects. Given that manual classification of issues is a tedious task and needs an expert domain knowledge, auto-classification is extremely needed. We considered different strategies and developed diverse text analytics techniques for automatic labelling issue reports of a GitHub\u2019s project. We applied J48, SMO, Na\u00efve Byes, and LibSVM algorithms so that different classification models are produced. Our results showed that SMO is able to label the issue reports with accuracy of 87.15 and F-measure of 0.869, when both the title and the body description of issues are considered in a balanced binary classification model."}]}]}]}}