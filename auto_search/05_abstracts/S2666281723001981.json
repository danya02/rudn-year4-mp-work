{"pii": "S2666281723001981", "abstracts": {"#name": "abstracts", "$": {"xmlns:ce": true, "xmlns:dm": true, "xmlns:sb": true}, "$$": [{"#name": "abstract", "$": {"lang": "en", "id": "abs0010", "view": "all", "class": "author"}, "$$": [{"#name": "section-title", "$": {"id": "sectitle0010"}, "_": "Abstract"}, {"#name": "abstract-sec", "$": {"id": "abssec0010", "view": "all"}, "$$": [{"#name": "simple-para", "$": {"id": "abspara0010", "view": "all"}, "_": "As automation within digital forensic tools becomes more advanced there is a need for a systematic approach to ensure the validity, reliability, and standardization of digital forensic results. This paper argues for intermediate output in a standardized format within digital forensic tools to allow a methodical approach to tool validation that targets errors at each stage of processing. To achieve this, a detailed process model of digital forensic analysis tools is created, extrapolating the details of the internal processes performed by monolithic forensic tools. The research deconstructs the process flow within tools and presents an \u2018abstract digital forensic tool\u2019, revisiting earlier abstraction layer ideas. This not only identifies the interconnected processes within tools but allows discussion of the potential error that could be introduced at each stage, and how it could potentially propagate within a tool. A demonstration, with a dataset, is also included, structurally annotated using Cyber-investigation Analysis Standard Expression (CASE)."}]}]}]}}